{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d82954",
   "metadata": {},
   "source": [
    "# Contexto del problema\n",
    "\n",
    "El dataset Churn_Modelling.csv representa información de clientes bancarios.\n",
    "Cada fila contiene variables demográficas y de comportamiento (edad, balance, productos, actividad, etc.) y una variable binaria:\n",
    "\n",
    "- Exited = 1 si el cliente se fue\n",
    "- Exited = 0 si permaneció\n",
    "\n",
    "Por tanto, estamos ante un problema de clasificación binaria supervisada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63314e99",
   "metadata": {},
   "source": [
    "# Criterios para la elección del modelo\n",
    "\n",
    "1. ROC - AUC\n",
    "  - Mide la capacidad del modelo para distinguir entre clases (0 = se queda, 1 = se va).\n",
    "  - Ideal cuando hay desbalance de clases.\n",
    "  - Un AUC > 0.85 suele considerarse excelente.\n",
    "\n",
    "2. F1-Score\n",
    "  - Equilibrio entre precision (no dar falsos positivos) y recall (detectar bien los positivos).\n",
    "  - Útil cuando ambos errores (falsos positivos y falsos negativos) son costosos  .\n",
    "\n",
    "3. Precision / Recall (según el caso de negocio)\n",
    "  - Precision alta: cuando es costoso contactar clientes que no se irán.\n",
    "  - Recall alto: cuando es más costoso perder clientes reales sin actuar.\n",
    "\n",
    "4. Accuracy\n",
    "  - Mide porcentaje de aciertos, pero no es confiable si las clases están desbalanceadas.\n",
    "  - Ejemplo: si solo el 20% se va, un modelo que siempre diga “no se va” tendrá 80% accuracy, pero 0 utilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1028113",
   "metadata": {},
   "source": [
    "# Criterios técnicos (comparativos)\n",
    "\n",
    "| Modelo                          | Mejor en...                            | Limitaciones                   | Cuándo elegirlo                                       |\n",
    "| ------------------------------- | -------------------------------------- | ------------------------------ | ----------------------------------------------------- |\n",
    "| **Regresión Logística**         | Interpretabilidad, velocidad           | Baja capacidad no lineal       | Si necesitas justificar decisiones (ej. regulaciones) |\n",
    "| **Árbol de Decisión**           | Explicabilidad, no requiere escalado   | Tiende a sobreajustar          | Si buscas reglas comprensibles                        |\n",
    "| **Random Forest**               | Precisión, robustez                    | Menor interpretabilidad        | Si buscas rendimiento sólido sin tuning complejo      |\n",
    "| **Gradient Boosting / XGBoost** | Máxima precisión, ajuste fino          | Requiere tuning y más CPU      | Si necesitas el mejor desempeño predictivo            |\n",
    "| **SVM**                         | Espacios complejos con pocas variables | Escala mal en grandes datasets | Si tu dataset es pequeño/mediano y limpio             |\n",
    "| **KNN**                         | Simplicidad, sin entrenamiento         | Costoso en predicción          | Si el dataset es pequeño y se prioriza simpleza       |\n",
    "| **MLP (Red Neuronal)**          | Patrones no lineales complejos         | Poca interpretabilidad         | Si tienes datos masivos o buscas precisión máxima     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7481ec",
   "metadata": {},
   "source": [
    "# Aplicado al dataset Churn_Modelling\n",
    "\n",
    "Objetivo: identificar clientes que abandonarán (Exited=1)\n",
    "\n",
    "Coste del error: perder un cliente sin detectarlo (falso negativo)\n",
    "\n",
    "Por tanto: priorizamos Recall y AUC, sin descuidar la precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee402d00",
   "metadata": {},
   "source": [
    "# Seleccionar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f27258",
   "metadata": {},
   "source": [
    "### Definir métrica de desempeño\n",
    "\n",
    "Del dataset se puede evidenciar una clasificación binario de clases desbalanceadas entre 80/20, lo cual indica que no solo con accuracy (si estuvieran balanceadas las clases sí) se puede medir el modelo.\n",
    "\n",
    "Métricas recomendadas para evaluación\n",
    "\n",
    "Accuracy: porcentaje de aciertos global.\n",
    "\n",
    "Precision: exactitud de los positivos predichos.\n",
    "\n",
    "Recall (Sensibilidad): capacidad para detectar positivos reales.\n",
    "\n",
    "F1-score: equilibrio entre precisión y recall.\n",
    "\n",
    "ROC-AUC: mide la capacidad general del modelo para discriminar entre las dos clases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c60896",
   "metadata": {},
   "source": [
    "Como la variable objetivo es variable dicotómica (0 o 1), se acotan los modelos a usar:\n",
    "| Tipo                              | Modelo                                     | Descripción                                                                                                                                                                                               |\n",
    "| --------------------------------- | ------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Lineales**                      | **Regresión Logística**                    | Es el modelo base para variables binarias. Calcula la probabilidad de pertenecer a la clase positiva mediante una función sigmoide. Es interpretable y muy usado en banca, salud, riesgo crediticio, etc. |\n",
    "| **No lineales (árboles)**         | **Árbol de Decisión**                      | Divide los datos según reglas lógicas (ej. “edad > 40”) hasta clasificar los casos. Intuitivo y explicable.                                                                                               |\n",
    "| **Ensamblados (mayor precisión)** | **Random Forest**                          | Combina múltiples árboles para reducir el error de un solo árbol. Mejora estabilidad y generalización.                                                                                                    |\n",
    "|                                   | **Gradient Boosting / XGBoost / LightGBM** | Ensambles secuenciales que optimizan el error del modelo previo. Ofrecen los mejores resultados predictivos en la mayoría de los problemas de clasificación binaria.                                      |\n",
    "| **Basados en distancia**          | **K-Nearest Neighbors (KNN)**              | Clasifica según los *k* vecinos más cercanos. Sencillo, aunque sensible al ruido y escalado.                                                                                                              |\n",
    "| **Margen máximo**                 | **Support Vector Machine (SVM)**           | Encuentra el hiperplano que mejor separa las clases. Muy eficaz en espacios con muchas variables.                                                                                                         |\n",
    "| **Neurales**                      | **Perceptrón Multicapa (MLPClassifier)**   | Red neuronal capaz de aprender relaciones complejas y no lineales. Requiere más datos y cómputo.                                                                                                          |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
