{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d82954",
   "metadata": {},
   "source": [
    "# Contexto del problema\n",
    "\n",
    "El dataset Churn_Modelling.csv representa información de clientes bancarios.\n",
    "Cada fila contiene variables demográficas y de comportamiento (edad, balance, productos, actividad, etc.) y una variable binaria:\n",
    "\n",
    "- Exited = 1 si el cliente se fue\n",
    "- Exited = 0 si permaneció\n",
    "\n",
    "Por tanto, estamos ante un problema de clasificación binaria supervisada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63314e99",
   "metadata": {},
   "source": [
    "# Criterios para la elección del modelo\n",
    "\n",
    "1. ROC - AUC\n",
    "  - Mide la capacidad del modelo para distinguir entre clases (0 = se queda, 1 = se va).\n",
    "  - Ideal cuando hay desbalance de clases.\n",
    "  - Un AUC > 0.85 suele considerarse excelente.\n",
    "\n",
    "2. F1-Score\n",
    "  - Equilibrio entre precision (no dar falsos positivos) y recall (detectar bien los positivos).\n",
    "  - Útil cuando ambos errores (falsos positivos y falsos negativos) son costosos  .\n",
    "\n",
    "3. Precision / Recall (según el caso de negocio)\n",
    "  - Precision alta: cuando es costoso contactar clientes que no se irán.\n",
    "  - Recall alto: cuando es más costoso perder clientes reales sin actuar.\n",
    "\n",
    "4. Accuracy\n",
    "  - Mide porcentaje de aciertos, pero no es confiable si las clases están desbalanceadas.\n",
    "  - Ejemplo: si solo el 20% se va, un modelo que siempre diga “no se va” tendrá 80% accuracy, pero 0 utilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1028113",
   "metadata": {},
   "source": [
    "# Criterios técnicos (comparativos)\n",
    "\n",
    "| Modelo                          | Mejor en...                            | Limitaciones                   | Cuándo elegirlo                                       |\n",
    "| ------------------------------- | -------------------------------------- | ------------------------------ | ----------------------------------------------------- |\n",
    "| **Regresión Logística**         | Interpretabilidad, velocidad           | Baja capacidad no lineal       | Si necesitas justificar decisiones (ej. regulaciones) |\n",
    "| **Árbol de Decisión**           | Explicabilidad, no requiere escalado   | Tiende a sobreajustar          | Si buscas reglas comprensibles                        |\n",
    "| **Random Forest**               | Precisión, robustez                    | Menor interpretabilidad        | Si buscas rendimiento sólido sin tuning complejo      |\n",
    "| **Gradient Boosting / XGBoost** | Máxima precisión, ajuste fino          | Requiere tuning y más CPU      | Si necesitas el mejor desempeño predictivo            |\n",
    "| **SVM**                         | Espacios complejos con pocas variables | Escala mal en grandes datasets | Si tu dataset es pequeño/mediano y limpio             |\n",
    "| **KNN**                         | Simplicidad, sin entrenamiento         | Costoso en predicción          | Si el dataset es pequeño y se prioriza simpleza       |\n",
    "| **MLP (Red Neuronal)**          | Patrones no lineales complejos         | Poca interpretabilidad         | Si tienes datos masivos o buscas precisión máxima     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ddd9e",
   "metadata": {},
   "source": [
    "# Estrategia de elección\n",
    "\n",
    "1. Entrena varios modelos base con hiperparámetros estándar.\n",
    "\n",
    "2. Evalúa métricas cruzadas (ROC-AUC, F1, Accuracy, Recall).\n",
    "\n",
    "3. Aplica validación cruzada (StratifiedKFold) → mide consistencia.\n",
    "\n",
    "4. Observa overfitting:\n",
    "  - Si el rendimiento en entrenamiento >> test → reducir complejidad o regularizar.\n",
    "\n",
    "5. Elige el modelo con:\n",
    "  - AUC alto (>0.85)\n",
    "  - Gap pequeño entre entrenamiento y test\n",
    "  - Métricas estables entre folds\n",
    "\n",
    "6. Si hay empate:\n",
    "  - Prefiere el modelo más simple e interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7481ec",
   "metadata": {},
   "source": [
    "# Aplicado al dataset Churn_Modelling\n",
    "\n",
    "Objetivo: identificar clientes que abandonarán (Exited=1)\n",
    "\n",
    "Coste del error: perder un cliente sin detectarlo (falso negativo)\n",
    "\n",
    "Por tanto: priorizamos Recall y AUC, sin descuidar la precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893fc842",
   "metadata": {},
   "source": [
    "Gradient Boosting (mejor AUC y Recall)\n",
    "\n",
    "Random Forest (muy robusto y explicable)\n",
    "\n",
    "Regresión Logística (referencia base e interpretable)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
