{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60dae98e",
   "metadata": {},
   "source": [
    "# Desempeño comparativo general\n",
    "\n",
    "| Modelo                |  Accuracy  | Precision(1) |  Recall(1) |    F1(1)   |   ROC-AUC  |\n",
    "| :-------------------- | :--------: | :----------: | :--------: | :--------: | :--------: |\n",
    "| **Gradient Boosting** | **0.8732** |    0.7874    | **0.5167** | **0.6240** | **0.8806** |\n",
    "| Random Forest         |   0.8664   |  **0.8159**  |   0.4440   |   0.5751   |   0.8677   |\n",
    "| Decision Tree         |   0.8648   |    0.7841    |   0.4637   |   0.5827   |   0.8496   |\n",
    "| SVM (RBF)             |   0.8632   |    0.7951    |   0.4420   |   0.5682   |   0.8515   |\n",
    "| Regresión Logística   |   0.8324   |    0.7083    |   0.3006   |   0.4221   |   0.8067   |\n",
    "| KNN (k=15)            |   0.8264   |    0.7698    |   0.2102   |   0.3302   |   0.7998   |\n",
    "| MLP (Red Neuronal)    |   0.8128   |    0.5451    |   0.4872   |   0.5145   |   0.7915   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d346e94",
   "metadata": {},
   "source": [
    "## Mejor modelo general: Gradient Boosting\n",
    "  - AUC más alto (0.8806) → mejor discriminación entre clientes que se van y los que permanecen.\n",
    "  - Mayor recall (0.5167) → detecta la mayor proporción de churners reales.\n",
    "  - F1 (0.6240) → equilibrio más consistente entre precisión y sensibilidad.\n",
    "\n",
    "Conclusión: ideal para un sistema de alerta temprana de churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15e7f8",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "  - Segunda mejor precisión (AUC=0.8677), con la mayor precisión (0.8159).\n",
    "  - Es más conservador: identifica menos churners (recall bajo) pero con menos falsos positivos.\n",
    "\n",
    "Recomendación: útil en escenarios donde es costoso contactar clientes erróneos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67208b3d",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "  - Resultados intermedios (AUC=0.8496) con buena precisión (0.7841) y recall moderado (0.4637).\n",
    "  - Su interpretabilidad lo convierte en una excelente herramienta para explicar reglas de decisión a áreas de negocio.\n",
    "  - Ideal como modelo explicativo complementario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59543ace",
   "metadata": {},
   "source": [
    "### SVM (RBF)\n",
    "  - Buen rendimiento general (AUC=0.8515), similar al Árbol de Decisión.\n",
    "  - Buen balance entre precisión y recall, pero mayor costo computacional.\n",
    "  - Recomendado para datasets medianos cuando se prioriza precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d3eb1",
   "metadata": {},
   "source": [
    "### Regresión Logística\n",
    "  - Cumple función de modelo base interpretativo.\n",
    "\n",
    "  - Menor recall (0.30) → no detecta muchos churners, pero su AUC (0.8067) demuestra buena capacidad lineal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1408fd",
   "metadata": {},
   "source": [
    "### KNN\n",
    "  - Menor recall (0.21) y F1 (0.33).\n",
    "\n",
    "  - Sensible a escalado y dimensionalidad → no recomendado para producción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5333c1",
   "metadata": {},
   "source": [
    "## Conclusiones finales\n",
    "\n",
    "1. El mejor modelo de predicción de churn es Gradient Boosting.\n",
    "2. Random Forest es una alternativa sólida y más interpretable.\n",
    "3. Decision Tree sirve como herramienta de apoyo para comunicar reglas a las áreas comerciales.\n",
    "4. Los modelos lineales o sencillos (KNN, LogReg), aunque más rápidos, no capturan la complejidad del fenómeno.\n",
    "5. El modelo neuronal (MLP) no mejoró los resultados, confirmando que el dataset no presenta patrones suficientemente no lineales."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
