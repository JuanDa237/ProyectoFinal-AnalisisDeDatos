{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final - Análisis de Datos\n",
    "\n",
    "Este notebook contiene un análisis completo de datos que abarca desde la recopilación y transformación hasta el modelado predictivo y conclusiones.\n",
    "\n",
    "**Autor:** [Tu Nombre]\n",
    "\n",
    "**Fecha:** [Fecha]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recopilación y Transformación de Datos (ETL)\n",
    "\n",
    "En esta sección se lleva a cabo el proceso de Extracción, Transformación y Carga (ETL) de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importación de Librerías\n",
    "\n",
    "Importamos las librerías necesarias para el proceso ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerías para visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Extracción de Datos\n",
    "\n",
    "Cargamos los datos desde las fuentes disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: Cargar datos desde un archivo CSV\n",
    "# df = pd.read_csv('ruta/al/archivo.csv')\n",
    "\n",
    "# O desde una URL\n",
    "# df = pd.read_csv('https://ejemplo.com/datos.csv')\n",
    "\n",
    "# O desde una base de datos\n",
    "# import sqlalchemy\n",
    "# engine = sqlalchemy.create_engine('conexión')\n",
    "# df = pd.read_sql('SELECT * FROM tabla', engine)\n",
    "\n",
    "print(\"Datos cargados exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Transformación de Datos\n",
    "\n",
    "Realizamos las transformaciones necesarias para preparar los datos para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de transformaciones comunes:\n",
    "\n",
    "# 1. Limpieza de datos\n",
    "# df = df.dropna()  # Eliminar valores nulos\n",
    "# df = df.drop_duplicates()  # Eliminar duplicados\n",
    "\n",
    "# 2. Conversión de tipos de datos\n",
    "# df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "# df['categoria'] = df['categoria'].astype('category')\n",
    "\n",
    "# 3. Creación de nuevas variables\n",
    "# df['nueva_columna'] = df['columna1'] + df['columna2']\n",
    "\n",
    "# 4. Normalización o estandarización\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# df['columna_normalizada'] = scaler.fit_transform(df[['columna']])\n",
    "\n",
    "print(\"Transformaciones aplicadas exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Carga de Datos\n",
    "\n",
    "Guardamos los datos transformados para su uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar datos procesados\n",
    "# df.to_csv('datos_procesados.csv', index=False)\n",
    "# df.to_parquet('datos_procesados.parquet')\n",
    "\n",
    "print(\"Datos guardados exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "En esta sección realizamos un análisis exploratorio para comprender las características principales de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visión General de los Datos\n",
    "\n",
    "Exploramos la estructura básica del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar primeras filas\n",
    "# df.head()\n",
    "\n",
    "# Información del dataset\n",
    "# df.info()\n",
    "\n",
    "# Dimensiones\n",
    "# print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "\n",
    "# Tipos de datos\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Estadísticas Descriptivas\n",
    "\n",
    "Calculamos estadísticas descriptivas para variables numéricas y categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas para variables numéricas\n",
    "# df.describe()\n",
    "\n",
    "# Estadísticas para variables categóricas\n",
    "# df.describe(include=['object', 'category'])\n",
    "\n",
    "# Valores únicos por columna\n",
    "# df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Análisis de Valores Faltantes\n",
    "\n",
    "Identificamos y analizamos valores faltantes en el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de valores nulos por columna\n",
    "# valores_nulos = df.isnull().sum()\n",
    "# porcentaje_nulos = (valores_nulos / len(df)) * 100\n",
    "# resumen_nulos = pd.DataFrame({\n",
    "#     'Valores_Nulos': valores_nulos,\n",
    "#     'Porcentaje': porcentaje_nulos\n",
    "# })\n",
    "# print(resumen_nulos[resumen_nulos['Valores_Nulos'] > 0])\n",
    "\n",
    "# Visualización de valores faltantes\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.heatmap(df.isnull(), cbar=False, yticklabels=False)\n",
    "# plt.title('Mapa de Valores Faltantes')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Distribución de Variables\n",
    "\n",
    "Analizamos la distribución de las variables principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas para variables numéricas\n",
    "# df.hist(figsize=(15, 10), bins=30)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Gráficos de caja (boxplots)\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "# for i, col in enumerate(df.select_dtypes(include=[np.number]).columns[:6]):\n",
    "#     ax = axes[i//3, i%3]\n",
    "#     df.boxplot(column=col, ax=ax)\n",
    "#     ax.set_title(f'Boxplot de {col}')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Análisis de Correlaciones\n",
    "\n",
    "Exploramos las relaciones entre variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "# correlacion = df.select_dtypes(include=[np.number]).corr()\n",
    "\n",
    "# Visualización de la matriz de correlación\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(correlacion, annot=True, cmap='coolwarm', center=0, \n",
    "#             square=True, linewidths=1, fmt='.2f')\n",
    "# plt.title('Matriz de Correlación')\n",
    "# plt.show()\n",
    "\n",
    "# Pairplot para variables seleccionadas\n",
    "# sns.pairplot(df[['var1', 'var2', 'var3', 'target']], hue='target')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Detección de Valores Atípicos (Outliers)\n",
    "\n",
    "Identificamos valores atípicos que podrían afectar el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método IQR para detectar outliers\n",
    "# def detectar_outliers_iqr(df, columna):\n",
    "#     Q1 = df[columna].quantile(0.25)\n",
    "#     Q3 = df[columna].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     limite_inferior = Q1 - 1.5 * IQR\n",
    "#     limite_superior = Q3 + 1.5 * IQR\n",
    "#     outliers = df[(df[columna] < limite_inferior) | (df[columna] > limite_superior)]\n",
    "#     return outliers\n",
    "\n",
    "# for col in df.select_dtypes(include=[np.number]).columns:\n",
    "#     outliers = detectar_outliers_iqr(df, col)\n",
    "#     print(f\"{col}: {len(outliers)} outliers detectados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Inteligencia de Negocios (BI)\n",
    "\n",
    "En esta sección generamos insights y métricas clave para la toma de decisiones empresariales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Indicadores Clave de Rendimiento (KPIs)\n",
    "\n",
    "Calculamos y visualizamos los KPIs principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de KPIs comunes:\n",
    "\n",
    "# Total de ventas, ingresos, clientes, etc.\n",
    "# kpi_total = df['ventas'].sum()\n",
    "# print(f\"Total de Ventas: ${kpi_total:,.2f}\")\n",
    "\n",
    "# Promedio\n",
    "# kpi_promedio = df['ventas'].mean()\n",
    "# print(f\"Venta Promedio: ${kpi_promedio:,.2f}\")\n",
    "\n",
    "# Tasa de crecimiento\n",
    "# tasa_crecimiento = ((df['ventas'].iloc[-1] - df['ventas'].iloc[0]) / df['ventas'].iloc[0]) * 100\n",
    "# print(f\"Tasa de Crecimiento: {tasa_crecimiento:.2f}%\")\n",
    "\n",
    "# Visualización de KPIs\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "# axes[0].text(0.5, 0.5, f'${kpi_total:,.0f}', ha='center', va='center', fontsize=24)\n",
    "# axes[0].set_title('Total de Ventas', fontsize=16)\n",
    "# axes[0].axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Segmentación de Clientes/Productos\n",
    "\n",
    "Realizamos segmentación para identificar grupos clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentación por categoría\n",
    "# segmentos = df.groupby('categoria').agg({\n",
    "#     'ventas': ['sum', 'mean', 'count'],\n",
    "#     'cliente_id': 'nunique'\n",
    "# }).round(2)\n",
    "# print(segmentos)\n",
    "\n",
    "# Visualización de segmentos\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# df.groupby('categoria')['ventas'].sum().sort_values(ascending=False).plot(kind='bar')\n",
    "# plt.title('Ventas por Categoría')\n",
    "# plt.xlabel('Categoría')\n",
    "# plt.ylabel('Ventas Totales')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Análisis de Tendencias Temporales\n",
    "\n",
    "Analizamos patrones y tendencias a lo largo del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series de tiempo\n",
    "# df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "# df_temporal = df.set_index('fecha')\n",
    "\n",
    "# Tendencia mensual\n",
    "# tendencia_mensual = df_temporal.resample('M')['ventas'].sum()\n",
    "\n",
    "# Visualización\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# tendencia_mensual.plot()\n",
    "# plt.title('Tendencia de Ventas Mensuales')\n",
    "# plt.xlabel('Fecha')\n",
    "# plt.ylabel('Ventas')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Media móvil\n",
    "# media_movil = tendencia_mensual.rolling(window=3).mean()\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(tendencia_mensual, label='Ventas Reales', alpha=0.7)\n",
    "# plt.plot(media_movil, label='Media Móvil (3 meses)', linewidth=2)\n",
    "# plt.title('Ventas con Media Móvil')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Dashboard de Métricas\n",
    "\n",
    "Creamos un dashboard visual con las métricas más importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dashboard con múltiples visualizaciones\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Gráfico 1: Top productos\n",
    "# df.groupby('producto')['ventas'].sum().nlargest(10).plot(kind='barh', ax=axes[0, 0])\n",
    "# axes[0, 0].set_title('Top 10 Productos por Ventas')\n",
    "\n",
    "# Gráfico 2: Distribución por región\n",
    "# df.groupby('region')['ventas'].sum().plot(kind='pie', ax=axes[0, 1], autopct='%1.1f%%')\n",
    "# axes[0, 1].set_title('Distribución de Ventas por Región')\n",
    "\n",
    "# Gráfico 3: Evolución temporal\n",
    "# df.groupby('fecha')['ventas'].sum().plot(ax=axes[1, 0])\n",
    "# axes[1, 0].set_title('Evolución de Ventas en el Tiempo')\n",
    "\n",
    "# Gráfico 4: Heatmap de rendimiento\n",
    "# pivot_data = df.pivot_table(values='ventas', index='mes', columns='año', aggfunc='sum')\n",
    "# sns.heatmap(pivot_data, annot=True, fmt='.0f', cmap='YlOrRd', ax=axes[1, 1])\n",
    "# axes[1, 1].set_title('Heatmap de Ventas por Mes y Año')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Análisis Comparativo\n",
    "\n",
    "Comparamos diferentes segmentos, periodos o categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación año contra año\n",
    "# df['año'] = df['fecha'].dt.year\n",
    "# comparacion_anual = df.groupby('año')['ventas'].agg(['sum', 'mean', 'count'])\n",
    "# print(comparacion_anual)\n",
    "\n",
    "# Gráfico de comparación\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# comparacion_anual['sum'].plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "# axes[0].set_title('Ventas Totales por Año')\n",
    "# axes[0].set_ylabel('Ventas')\n",
    "\n",
    "# comparacion_anual['mean'].plot(kind='bar', ax=axes[1], color='coral')\n",
    "# axes[1].set_title('Venta Promedio por Año')\n",
    "# axes[1].set_ylabel('Venta Promedio')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Modelado Predictivo\n",
    "\n",
    "En esta sección desarrollamos modelos de machine learning para realizar predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Preparación de Datos para Modelado\n",
    "\n",
    "Preparamos los datos específicamente para el modelado predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías de machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Selección de features y target\n",
    "# features = ['feature1', 'feature2', 'feature3']\n",
    "# X = df[features]\n",
    "# y = df['target']\n",
    "\n",
    "# División en conjunto de entrenamiento y prueba\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalado de features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "# print(f\"Tamaño del conjunto de prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Selección de Características\n",
    "\n",
    "Identificamos las características más relevantes para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de características usando Random Forest\n",
    "# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# Para regresión:\n",
    "# rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# Para clasificación:\n",
    "# rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# Importancia de características\n",
    "# importancia = pd.DataFrame({\n",
    "#     'Feature': features,\n",
    "#     'Importancia': rf.feature_importances_\n",
    "# }).sort_values('Importancia', ascending=False)\n",
    "\n",
    "# print(importancia)\n",
    "\n",
    "# Visualización\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.barh(importancia['Feature'], importancia['Importancia'])\n",
    "# plt.xlabel('Importancia')\n",
    "# plt.title('Importancia de Características')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Entrenamiento de Modelos\n",
    "\n",
    "Entrenamos y comparamos diferentes modelos de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "# print(\"Regresión Lineal:\")\n",
    "# print(f\"R² Score: {r2_score(y_test, y_pred_lr):.4f}\")\n",
    "# print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lr)):.4f}\")\n",
    "# print(f\"MAE: {mean_absolute_error(y_test, y_pred_lr):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# rf_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# print(\"Random Forest:\")\n",
    "# print(f\"R² Score: {r2_score(y_test, y_pred_rf):.4f}\")\n",
    "# print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.4f}\")\n",
    "# print(f\"MAE: {mean_absolute_error(y_test, y_pred_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "# gb_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# print(\"Gradient Boosting:\")\n",
    "# print(f\"R² Score: {r2_score(y_test, y_pred_gb):.4f}\")\n",
    "# print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_gb)):.4f}\")\n",
    "# print(f\"MAE: {mean_absolute_error(y_test, y_pred_gb):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Validación y Evaluación de Modelos\n",
    "\n",
    "Evaluamos el rendimiento de los modelos con métricas apropiadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación de modelos\n",
    "# resultados = pd.DataFrame({\n",
    "#     'Modelo': ['Regresión Lineal', 'Random Forest', 'Gradient Boosting'],\n",
    "#     'R²': [r2_score(y_test, y_pred_lr), \n",
    "#            r2_score(y_test, y_pred_rf), \n",
    "#            r2_score(y_test, y_pred_gb)],\n",
    "#     'RMSE': [np.sqrt(mean_squared_error(y_test, y_pred_lr)),\n",
    "#              np.sqrt(mean_squared_error(y_test, y_pred_rf)),\n",
    "#              np.sqrt(mean_squared_error(y_test, y_pred_gb))],\n",
    "#     'MAE': [mean_absolute_error(y_test, y_pred_lr),\n",
    "#             mean_absolute_error(y_test, y_pred_rf),\n",
    "#             mean_absolute_error(y_test, y_pred_gb)]\n",
    "# })\n",
    "\n",
    "# print(resultados)\n",
    "\n",
    "# Visualización de comparación\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "# resultados.plot(x='Modelo', y='R²', kind='bar', ax=axes[0], legend=False)\n",
    "# axes[0].set_title('R² Score por Modelo')\n",
    "# axes[0].set_ylabel('R²')\n",
    "\n",
    "# resultados.plot(x='Modelo', y='RMSE', kind='bar', ax=axes[1], legend=False, color='orange')\n",
    "# axes[1].set_title('RMSE por Modelo')\n",
    "# axes[1].set_ylabel('RMSE')\n",
    "\n",
    "# resultados.plot(x='Modelo', y='MAE', kind='bar', ax=axes[2], legend=False, color='green')\n",
    "# axes[2].set_title('MAE por Modelo')\n",
    "# axes[2].set_ylabel('MAE')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Validación Cruzada\n",
    "\n",
    "Aplicamos validación cruzada para evaluar la robustez del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada con 5 folds\n",
    "# cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, \n",
    "#                             scoring='r2')\n",
    "\n",
    "# print(f\"Scores de validación cruzada: {cv_scores}\")\n",
    "# print(f\"Score promedio: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Visualización\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.boxplot([cv_scores])\n",
    "# plt.title('Distribución de Scores de Validación Cruzada')\n",
    "# plt.ylabel('R² Score')\n",
    "# plt.xticks([1], ['Random Forest'])\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Optimización de Hiperparámetros\n",
    "\n",
    "Optimizamos los hiperparámetros del mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir grid de hiperparámetros\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [5, 10, 15, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# Grid search\n",
    "# grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "#                           param_grid=param_grid,\n",
    "#                           cv=5,\n",
    "#                           n_jobs=-1,\n",
    "#                           scoring='r2',\n",
    "#                           verbose=1)\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Mejores hiperparámetros:\")\n",
    "# print(grid_search.best_params_)\n",
    "# print(f\"\\nMejor score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Modelo optimizado\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# print(\"\\nRendimiento del modelo optimizado:\")\n",
    "# print(f\"R² Score: {r2_score(y_test, y_pred_best):.4f}\")\n",
    "# print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_best)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Visualización de Predicciones\n",
    "\n",
    "Visualizamos las predicciones del modelo versus los valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de valores reales vs predicciones\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(y_test, y_pred_best, alpha=0.5)\n",
    "# plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "# plt.xlabel('Valores Reales')\n",
    "# plt.ylabel('Predicciones')\n",
    "# plt.title('Valores Reales vs Predicciones')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Residuos\n",
    "# residuos = y_test - y_pred_best\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(y_pred_best, residuos, alpha=0.5)\n",
    "# plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "# plt.xlabel('Valores Predichos')\n",
    "# plt.ylabel('Residuos')\n",
    "# plt.title('Gráfico de Residuos')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Interpretación del Modelo\n",
    "\n",
    "Interpretamos los resultados del modelo y su significado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de errores por segmento\n",
    "# errores_df = pd.DataFrame({\n",
    "#     'Real': y_test,\n",
    "#     'Predicción': y_pred_best,\n",
    "#     'Error_Absoluto': np.abs(y_test - y_pred_best),\n",
    "#     'Error_Porcentual': np.abs((y_test - y_pred_best) / y_test) * 100\n",
    "# })\n",
    "\n",
    "# print(\"Estadísticas de error:\")\n",
    "# print(errores_df.describe())\n",
    "\n",
    "# Casos con mayor error\n",
    "# print(\"\\nTop 10 casos con mayor error:\")\n",
    "# print(errores_df.nlargest(10, 'Error_Absoluto'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Conclusiones y Recomendaciones\n",
    "\n",
    "En esta sección resumimos los hallazgos principales y proporcionamos recomendaciones accionables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Resumen de Hallazgos Principales\n",
    "\n",
    "**Principales insights del análisis:**\n",
    "\n",
    "1. **Calidad de los Datos:**\n",
    "   - [Describir la calidad general de los datos]\n",
    "   - [Mencionar problemas encontrados y cómo se manejaron]\n",
    "   - [Comentar sobre valores faltantes y outliers]\n",
    "\n",
    "2. **Análisis Exploratorio:**\n",
    "   - [Describir patrones principales encontrados]\n",
    "   - [Mencionar correlaciones importantes]\n",
    "   - [Destacar distribuciones relevantes]\n",
    "\n",
    "3. **Inteligencia de Negocios:**\n",
    "   - [KPIs más importantes identificados]\n",
    "   - [Segmentos de mayor valor]\n",
    "   - [Tendencias temporales observadas]\n",
    "\n",
    "4. **Modelado Predictivo:**\n",
    "   - [Rendimiento del mejor modelo]\n",
    "   - [Variables más importantes para la predicción]\n",
    "   - [Precisión y confiabilidad de las predicciones]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Recomendaciones Estratégicas\n",
    "\n",
    "**Recomendaciones basadas en los resultados del análisis:**\n",
    "\n",
    "1. **Corto Plazo (0-3 meses):**\n",
    "   - [Acción específica 1]\n",
    "   - [Acción específica 2]\n",
    "   - [Acción específica 3]\n",
    "\n",
    "2. **Mediano Plazo (3-6 meses):**\n",
    "   - [Estrategia específica 1]\n",
    "   - [Estrategia específica 2]\n",
    "   - [Estrategia específica 3]\n",
    "\n",
    "3. **Largo Plazo (6-12 meses):**\n",
    "   - [Iniciativa estratégica 1]\n",
    "   - [Iniciativa estratégica 2]\n",
    "   - [Iniciativa estratégica 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Áreas de Mejora y Próximos Pasos\n",
    "\n",
    "**Oportunidades de mejora identificadas:**\n",
    "\n",
    "1. **Mejora en la Recopilación de Datos:**\n",
    "   - [Sugerencia 1]\n",
    "   - [Sugerencia 2]\n",
    "\n",
    "2. **Optimización del Modelo:**\n",
    "   - [Propuesta 1: explorar otros algoritmos]\n",
    "   - [Propuesta 2: incluir nuevas variables]\n",
    "   - [Propuesta 3: mejorar feature engineering]\n",
    "\n",
    "3. **Implementación y Monitoreo:**\n",
    "   - [Plan de implementación]\n",
    "   - [Métricas de seguimiento]\n",
    "   - [Frecuencia de actualización del modelo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Impacto Esperado\n",
    "\n",
    "**Beneficios esperados de la implementación:**\n",
    "\n",
    "- **Impacto Financiero:**\n",
    "  - [Estimación de impacto en ingresos/costos]\n",
    "  - [ROI esperado]\n",
    "\n",
    "- **Impacto Operacional:**\n",
    "  - [Mejoras en eficiencia]\n",
    "  - [Optimización de procesos]\n",
    "\n",
    "- **Impacto Estratégico:**\n",
    "  - [Ventajas competitivas]\n",
    "  - [Capacidad de toma de decisiones]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Limitaciones del Análisis\n",
    "\n",
    "**Es importante reconocer las limitaciones:**\n",
    "\n",
    "1. [Limitación relacionada con los datos disponibles]\n",
    "2. [Limitación del alcance temporal]\n",
    "3. [Limitación metodológica]\n",
    "4. [Supuestos realizados en el modelado]\n",
    "5. [Factores externos no considerados]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Conclusión Final\n",
    "\n",
    "[Incluir aquí una conclusión general que sintetice los puntos más importantes del análisis y refuerce las recomendaciones clave para la toma de decisiones.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Referencias y Recursos\n",
    "\n",
    "- [Fuentes de datos utilizadas]\n",
    "- [Documentación técnica relevante]\n",
    "- [Artículos o papers de referencia]\n",
    "- [Herramientas y bibliotecas utilizadas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Anexos\n",
    "\n",
    "### A. Código de Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones auxiliares utilizadas en el análisis\n",
    "\n",
    "def limpiar_datos(df):\n",
    "    \"\"\"\n",
    "    Función para limpiar el dataframe\n",
    "    \"\"\"\n",
    "    # Implementación\n",
    "    return df\n",
    "\n",
    "def calcular_metricas(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Función para calcular métricas de evaluación\n",
    "    \"\"\"\n",
    "    metricas = {\n",
    "        'r2': r2_score(y_true, y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'mae': mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "    return metricas\n",
    "\n",
    "def visualizar_resultados(df, columna):\n",
    "    \"\"\"\n",
    "    Función para visualizar resultados\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df[columna].plot()\n",
    "    plt.title(f'Visualización de {columna}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Configuración del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del entorno de trabajo\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Configuración de matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "np.random.seed(42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
